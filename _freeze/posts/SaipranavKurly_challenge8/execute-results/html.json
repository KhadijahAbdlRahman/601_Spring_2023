{
  "hash": "a137fcf93028e9211466c9d6f498e4e6",
  "result": {
    "markdown": "---\ntitle: \"Challenge 8 Instructions\"\nauthor: \"Sai Pranav Kurly\"\ndescription: \"Joining Data\"\ndate: \"05/15/2023\"\nformat:\n  html:\n    toc: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_8\n  - railroads\n  - snl\n  - faostat\n  - debt\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1)  read in multiple data sets, and describe the data set using both words and any supporting information (e.g., tables, etc)\n2)  tidy data (as needed, including sanity checks)\n3)  mutate variables as needed (including sanity checks)\n4)  join two or more data sets and analyze some aspect of the joined data\n\n(be sure to only include the category tags for the data you use!)\n\n## Read in data\n\nRead in one (or more) of the following datasets, using the correct R package and command.\n\n  - military marriages ⭐⭐\n  - faostat ⭐⭐\n  - railroads  ⭐⭐⭐\n  - fed_rate ⭐⭐⭐\n  - debt ⭐⭐⭐\n  - us_hh ⭐⭐⭐⭐\n  - snl ⭐⭐⭐⭐⭐\n\nI'm planning to use the SNL data:\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_actors <- read_csv(\"_data/snl_actors.csv\")\nhead(snl_actors)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  aid            url           type  gender \n  <chr>          <chr>         <chr> <chr>  \n1 Kate McKinnon  /Cast/?KaMc   cast  female \n2 Alex Moffat    /Cast/?AlMo   cast  male   \n3 Ego Nwodim     /Cast/?EgNw   cast  unknown\n4 Chris Redd     /Cast/?ChRe   cast  male   \n5 Kenan Thompson /Cast/?KeTh   cast  male   \n6 Carey Mulligan /Guests/?3677 guest andy   \n```\n:::\n\n```{.r .cell-code}\ndim(snl_actors)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2306    4\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_casts <- read_csv(\"_data/snl_casts.csv\")\nhead(snl_casts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 8\n  aid                sid featured first_epid last_epid update_…¹ n_epi…² seaso…³\n  <chr>            <dbl> <lgl>         <dbl>     <dbl> <lgl>       <dbl>   <dbl>\n1 A. Whitney Brown    11 TRUE       19860222        NA FALSE           8   0.444\n2 A. Whitney Brown    12 TRUE             NA        NA FALSE          20   1    \n3 A. Whitney Brown    13 TRUE             NA        NA FALSE          13   1    \n4 A. Whitney Brown    14 TRUE             NA        NA FALSE          20   1    \n5 A. Whitney Brown    15 TRUE             NA        NA FALSE          20   1    \n6 A. Whitney Brown    16 TRUE             NA        NA FALSE          20   1    \n# … with abbreviated variable names ¹​update_anchor, ²​n_episodes,\n#   ³​season_fraction\n```\n:::\n\n```{.r .cell-code}\ndim(snl_casts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 614   8\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_seasons <- read_csv(\"_data/snl_seasons.csv\")\nhead(snl_seasons)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n    sid  year first_epid last_epid n_episodes\n  <dbl> <dbl>      <dbl>     <dbl>      <dbl>\n1     1  1975   19751011  19760731         24\n2     2  1976   19760918  19770521         22\n3     3  1977   19770924  19780520         20\n4     4  1978   19781007  19790526         20\n5     5  1979   19791013  19800524         20\n6     6  1980   19801115  19810411         13\n```\n:::\n\n```{.r .cell-code}\ndim(snl_seasons)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 46  5\n```\n:::\n:::\n\n### Briefly describe the data\nThis dataset contains information on the casts of Saturday Night Live from 1975 to 2020. Each row of this newly created dataframe represents a distinct actor-season pairing, complete with information on the actor and the SNL seasons in which they have appeared. Each row includes information about the actor's gender, whether they appeared in a specific season, the date of their first episode, the date of their last episode, the number of episodes they've appeared in, the percentage of each season they've appeared in, a URL for that actor, whether they were a member of the cast or a guest on the show, and whether they were an anchor on weekend update. \n\n## Tidy Data (as needed)\n\nWe can check for N/A and get rid of them in all the datasets. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_actors <- snl_actors %>%\n  drop_na()\nsnl_actors\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,249 × 4\n   aid            url           type  gender \n   <chr>          <chr>         <chr> <chr>  \n 1 Kate McKinnon  /Cast/?KaMc   cast  female \n 2 Alex Moffat    /Cast/?AlMo   cast  male   \n 3 Ego Nwodim     /Cast/?EgNw   cast  unknown\n 4 Chris Redd     /Cast/?ChRe   cast  male   \n 5 Kenan Thompson /Cast/?KeTh   cast  male   \n 6 Carey Mulligan /Guests/?3677 guest andy   \n 7 Marcus Mumford /Guests/?3679 guest male   \n 8 Aidy Bryant    /Cast/?AiBr   cast  female \n 9 Steve Higgins  /Crew/?StHi   crew  male   \n10 Mikey Day      /Cast/?MiDa   cast  male   \n# … with 2,239 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_casts <- snl_casts %>%\n  select(aid, sid, featured, update_anchor, n_episodes, season_fraction)\nsnl_casts <- snl_casts %>%\n  drop_na()\nsnl_casts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 614 × 6\n   aid                sid featured update_anchor n_episodes season_fraction\n   <chr>            <dbl> <lgl>    <lgl>              <dbl>           <dbl>\n 1 A. Whitney Brown    11 TRUE     FALSE                  8           0.444\n 2 A. Whitney Brown    12 TRUE     FALSE                 20           1    \n 3 A. Whitney Brown    13 TRUE     FALSE                 13           1    \n 4 A. Whitney Brown    14 TRUE     FALSE                 20           1    \n 5 A. Whitney Brown    15 TRUE     FALSE                 20           1    \n 6 A. Whitney Brown    16 TRUE     FALSE                 20           1    \n 7 Alan Zweibel         5 TRUE     FALSE                  5           0.25 \n 8 Sasheer Zamata      39 TRUE     FALSE                 11           0.524\n 9 Sasheer Zamata      40 TRUE     FALSE                 21           1    \n10 Sasheer Zamata      41 FALSE    FALSE                 21           1    \n# … with 604 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_seasons <- snl_seasons %>% \n  drop_na()\nsnl_seasons\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 46 × 5\n     sid  year first_epid last_epid n_episodes\n   <dbl> <dbl>      <dbl>     <dbl>      <dbl>\n 1     1  1975   19751011  19760731         24\n 2     2  1976   19760918  19770521         22\n 3     3  1977   19770924  19780520         20\n 4     4  1978   19781007  19790526         20\n 5     5  1979   19791013  19800524         20\n 6     6  1980   19801115  19810411         13\n 7     7  1981   19811003  19820522         20\n 8     8  1982   19820925  19830514         20\n 9     9  1983   19831008  19840512         19\n10    10  1984   19841006  19850413         17\n# … with 36 more rows\n```\n:::\n:::\n\n\n## Join Data\n\nWe can join all 3 datasets and then analyze\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsnl_actors_casts <- snl_actors %>%\n  inner_join(snl_casts, by=\"aid\")\n\nsnl_actors_casts_seasons <- snl_actors_casts %>%\n  inner_join(snl_seasons, by=\"sid\")\nsnl_actors_casts_seasons\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 607 × 13\n   aid    url   type  gender   sid featu…¹ updat…² n_epi…³ seaso…⁴  year first…⁵\n   <chr>  <chr> <chr> <chr>  <dbl> <lgl>   <lgl>     <dbl>   <dbl> <dbl>   <dbl>\n 1 Kate … /Cas… cast  female    37 TRUE    FALSE         5   0.227  2011  2.01e7\n 2 Kate … /Cas… cast  female    38 TRUE    FALSE        21   1      2012  2.01e7\n 3 Kate … /Cas… cast  female    39 FALSE   FALSE        21   1      2013  2.01e7\n 4 Kate … /Cas… cast  female    40 FALSE   FALSE        21   1      2014  2.01e7\n 5 Kate … /Cas… cast  female    41 FALSE   FALSE        21   1      2015  2.02e7\n 6 Kate … /Cas… cast  female    42 FALSE   FALSE        21   1      2016  2.02e7\n 7 Kate … /Cas… cast  female    43 FALSE   FALSE        21   1      2017  2.02e7\n 8 Kate … /Cas… cast  female    44 FALSE   FALSE        21   1      2018  2.02e7\n 9 Kate … /Cas… cast  female    45 FALSE   FALSE        18   1      2019  2.02e7\n10 Kate … /Cas… cast  female    46 FALSE   FALSE        17   1      2020  2.02e7\n# … with 597 more rows, 2 more variables: last_epid <dbl>, n_episodes.y <dbl>,\n#   and abbreviated variable names ¹​featured, ²​update_anchor, ³​n_episodes.x,\n#   ⁴​season_fraction, ⁵​first_epid\n```\n:::\n:::\n\n\n\nWith the below plot we can see how analyze SNL cast by their gender per season\n\n::: {.cell}\n\n```{.r .cell-code}\ngraph <- ggplot(snl_actors_casts_seasons, aes(sid, fill = gender)) +\n  geom_bar() +\n  labs(\n    title = \"SNL Cast by Gender per Season\",\n    x = \"Season\",\n    y = \"Count\",\n    fill = \"Gender\"\n  ) \ngraph\n```\n\n::: {.cell-output-display}\n![](SaipranavKurly_challenge8_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nWith the below plot we can see the top 10 actors based on number of performances\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the number of times each actor acted in each year\nactor_counts <- snl_actors_casts_seasons %>%\n  group_by(aid) %>%\n  summarise(count = n())\n\ntop_10_actors <- actor_counts %>%\n  arrange(desc(count)) %>%\n  head(10)\n\n# Create the graph\ngraph <- ggplot(top_10_actors, aes(x = aid, y = count)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Top 10 actors based on number of performances\",\n    x = \"Actor\",\n    y = \"Count\",\n  ) + theme(axis.text.x = element_text(angle = 90))\ngraph\n```\n\n::: {.cell-output-display}\n![](SaipranavKurly_challenge8_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "SaipranavKurly_challenge8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}