{
  "hash": "731704ff7a66e9bf3b375751fb038cf3",
  "result": {
    "markdown": "---\ntitle: \"PoChunYang_Challenge 2\"\nauthor: \"PoChun Yang\"\ndesription: \"StateCounty2012.xls_Data wrangling\"\ndate: \"02/27/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_2\n  - railroads\n  - PoChunYang\n  - tidyverse\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(summarytools)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to\n\n1)  read in a data set, and describe the data using both words and any supporting information (e.g., tables, etc)\n2)  provide summary statistics for different interesting groups within the data, and interpret those statistics\n\n## Read in the Data\n\nRead in one (or more) of the following data sets, available in the `posts/_data` folder, using the correct R package and command.\n\n-   railroad\\*.csv or StateCounty2012.xls ⭐\n-   FAOstat\\*.csv or birds.csv ⭐⭐⭐\n-   hotel_bookings.csv ⭐⭐⭐⭐\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatecounty<- read_xls(\"_data/StateCounty2012.xls\",skip=3)\ndim(statecounty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2990    5\n```\n:::\n\n```{.r .cell-code}\ncolnames(statecounty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"STATE\"  \"...2\"   \"COUNTY\" \"...4\"   \"TOTAL\" \n```\n:::\n:::\n\n\nAdd any comments or documentation as needed. More challenging data may require additional code chunks and documentation.\n\n## Describe the data\n\nUsing a combination of words and results of R commands, can you provide a high level description of the data? Describe as efficiently as possible where/how the data was (likely) gathered, indicate the cases and variables (both the interpretation and any details you deem useful to the reader to fully understand your chosen data).\n\nWhen I used the dfSummary, I got the all the summary of the StateCounty2012.xls. However, there are a lot of strange things. For example, the max of total railroad employment is 255432. Then, I check the number of the files. It is the grand total. Thus, I used the some command to solve those problems.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfSummary(statecounty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData Frame Summary  \nstatecounty  \nDimensions: 2990 x 5  \nDuplicates: 2  \n\n---------------------------------------------------------------------------------------------------------------\nNo   Variable      Stats / Values               Freqs (% of Valid)    Graph                Valid     Missing   \n---- ------------- ---------------------------- --------------------- -------------------- --------- ----------\n1    STATE         1. TX                         221 ( 7.4%)          I                    2987      3         \n     [character]   2. GA                         152 ( 5.1%)          I                    (99.9%)   (0.1%)    \n                   3. KY                         119 ( 4.0%)                                                   \n                   4. MO                         115 ( 3.9%)                                                   \n                   5. IL                         103 ( 3.4%)                                                   \n                   6. IA                          99 ( 3.3%)                                                   \n                   7. KS                          95 ( 3.2%)                                                   \n                   8. NC                          94 ( 3.1%)                                                   \n                   9. IN                          92 ( 3.1%)                                                   \n                   10. VA                         92 ( 3.1%)                                                   \n                   [ 100 others ]               1805 (60.4%)          IIIIIIIIIIII                             \n\n2    ...2          All NA's                                                                0         2990      \n     [logical]                                                                             (0.0%)    (100.0%)  \n\n3    COUNTY        1. WASHINGTON                  31 ( 1.1%)                               2930      60        \n     [character]   2. JEFFERSON                   26 ( 0.9%)                               (98.0%)   (2.0%)    \n                   3. FRANKLIN                    24 ( 0.8%)                                                   \n                   4. LINCOLN                     24 ( 0.8%)                                                   \n                   5. JACKSON                     22 ( 0.8%)                                                   \n                   6. MADISON                     19 ( 0.6%)                                                   \n                   7. MONTGOMERY                  18 ( 0.6%)                                                   \n                   8. CLAY                        17 ( 0.6%)                                                   \n                   9. MARION                      17 ( 0.6%)                                                   \n                   10. MONROE                     17 ( 0.6%)                                                   \n                   [ 1699 others ]              2715 (92.7%)          IIIIIIIIIIIIIIIIII                       \n\n4    ...4          All NA's                                                                0         2990      \n     [logical]                                                                             (0.0%)    (100.0%)  \n\n5    TOTAL         Mean (sd) : 256.9 (4764.1)   452 distinct values   :                    2985      5         \n     [numeric]     min < med < max:                                   :                    (99.8%)   (0.2%)    \n                   1 < 22 < 255432                                    :                                        \n                   IQR (CV) : 64 (18.5)                               :                                        \n                                                                      :                                        \n---------------------------------------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n## Provide Grouped Summary Statistics\n\nConduct some exploratory data analysis, using dplyr commands such as `group_by()`, `select()`, `filter()`, and `summarise()`. Find the central tendency (mean, median, mode) and dispersion (standard deviation, mix/max/quantile) for different subgroups within the data set.\n\nFirst of all, I used cleancolumns to make the data is to read it. Then, I want to remove all the state_total rows. Next, used the group_by and summerise to get some of the detail of all the state. I am interested in NY state of railroad information so I used the filter command to do it. As below of form, there are 61 county of New York states. Besides that, the maximum of county's railraod employment is 3685.\nIn California state, there are 55 County that the summary gave us. Moreover, the minimum, maximum, mean, median county's railroad employment are respectively 1, 2888, 238.9, and 61.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncleancolumns <- select(statecounty,\"STATE\",\"COUNTY\",\"TOTAL\")\nfix_data <- na.omit(cleancolumns)\nfix_data%>%\n  group_by(STATE)%>%\n  summarise(total = sum(TOTAL), meantotal=mean(TOTAL),mediantotal = median(TOTAL),\n            modetotal = mode(TOTAL),deviationtotal = sd(TOTAL), maxtotal = max(TOTAL),\n            mintotal = min(TOTAL))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 53 × 8\n   STATE total meantotal mediantotal modetotal deviationtotal maxtotal mintotal\n   <chr> <dbl>     <dbl>       <dbl> <chr>              <dbl>    <dbl>    <dbl>\n 1 AE        2       2           2   numeric             NA          2        2\n 2 AK      103      17.2         2.5 numeric             34.8       88        1\n 3 AL     4257      63.5        26   numeric            130.       990        1\n 4 AP        1       1           1   numeric             NA          1        1\n 5 AR     3871      53.8        16.5 numeric            131.       972        1\n 6 AZ     3153     210.         94   numeric            228.       749        3\n 7 CA    13137     239.         61   numeric            549.      2888        1\n 8 CO     3650      64.0        10   numeric            128.       553        1\n 9 CT     2592     324         125   numeric            520.      1561       26\n10 DC      279     279         279   numeric             NA        279      279\n# … with 43 more rows\n```\n:::\n\n```{.r .cell-code}\nNY<-filter(fix_data,STATE == \"NY\")\nsummary(NY)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    STATE              COUNTY              TOTAL       \n Length:61          Length:61          Min.   :   5.0  \n Class :character   Class :character   1st Qu.:  27.0  \n Mode  :character   Mode  :character   Median :  71.0  \n                                       Mean   : 279.5  \n                                       3rd Qu.: 196.0  \n                                       Max.   :3685.0  \n```\n:::\n\n```{.r .cell-code}\nCA<-filter(fix_data,STATE == \"CA\")\nsummary(CA)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    STATE              COUNTY              TOTAL       \n Length:55          Length:55          Min.   :   1.0  \n Class :character   Class :character   1st Qu.:  12.5  \n Mode  :character   Mode  :character   Median :  61.0  \n                                       Mean   : 238.9  \n                                       3rd Qu.: 200.5  \n                                       Max.   :2888.0  \n```\n:::\n:::\n\n\n### Explain and Interpret\n\nBe sure to explain why you choose a specific group. Comment on the interpretation of any interesting differences between groups that you uncover. This section can be integrated with the exploratory data analysis, just be sure it is included.\n",
    "supporting": [
      "PoChunYang_Challenge2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}